[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Posts",
    "section": "",
    "text": "Computer Science to Machine Learning - An intuitive understanding of ML for coders (Part 1)\n\n\n\n\n\n\n\ntutorial\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2023\n\n\nJax Bulbrook\n\n\n\n\n\n\n  \n\n\n\n\nAttention is all you need\n\n\n\n\n\n\n\npaper\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2023\n\n\nJax Bulbrook\n\n\n\n\n\n\n  \n\n\n\n\nMath function classifier with Pytorch\n\n\n\n\n\n\n\nproject\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2023\n\n\nJax Bulbrook\n\n\n\n\n\n\n  \n\n\n\n\nImageNet Classification with Deep Convolutional Neural Networks\n\n\n\n\n\n\n\nproject\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2023\n\n\nJax Bulbrook\n\n\n\n\n\n\n  \n\n\n\n\nUsing a neural network to predict poisonous fruit\n\n\n\n\n\n\n\nproject\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2023\n\n\nJax Bulbrook\n\n\n\n\n\n\n  \n\n\n\n\nGetting started with a Quarto blog\n\n\n\n\n\n\n\ntutorial\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2023\n\n\nJax Bulbrook\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/visualizing-convnets/index.html",
    "href": "posts/visualizing-convnets/index.html",
    "title": "Day 3 - Visualizing and Understanding Convolutional Networks",
    "section": "",
    "text": "Summary\nThis paper presents a deconvnet layer to deconstruct the models predictions back into the original image, with the ability to see features. They attach a deconvnet to each layer, providing a way back to the original image to see which features were used. Pooling, though, takes the average, so how is that deconstructed? They introduce switch variables. This new way of deconstructing features allows us to see exactly what each part of the model is doing, and check for dead layers. It also proved that the models do detect the object itself, not just the environment around it, because when the object was covered it made incorrect predictions. This prevents guess and check, as we know exactly what goes wrong with the model. For example, the previous state of the art had issues with too large of a kernel size and stride in it’s first layers, causing them to have artifacts. By correcting this, they were able to achieve the new state of the art.\n\n\nTakeaway\nThis paper presents a new way to see the features of convolutional neural networks. This is a very interesting paper, as it allows for understanding of the models we build, which is a big problem today. I wonder if that is possible to do for Transformers. Is there some way to see the context, like seeing what it recognizes at individual layers? I will have to look into it more, but overall great paper!\nI am also shocked by the state of the art at their time. They used a GTX 580, which by comparison to today is an incredibly weak GPU. Even the one in my home computer is better than that, and I built this years ago!\n\n\nOther research\nI need to research statistics more, it seems like a major field I’ve barely scratched the surface of. What is a Linear SVM?"
  },
  {
    "objectID": "posts/character-level-language-model/index.html",
    "href": "posts/character-level-language-model/index.html",
    "title": "Day 10 - Character-Level Language Modeling with Deeper Self-Attention",
    "section": "",
    "text": "Summary\nThis was about a character-level model Transformer, replacing the state of the art for character-level modelling compared to RNNs. It was unfortunately still lacking when compared to word-level models, but a good improvement in the character space. It used several state of the art training methods, like momentum, dropout, auxilary losses, positional embeddings, and more.\nAn interesting point that they pointed out was that when the model saw some text containing elizabeth, it was trained to predict elizabeth in that context, but when they replaced it with a random string of letters, it instantly knew after seeing the first letter and the text that it needed to fill in the rest from the text, rather than using what it was trained on. They did this again for later text, and it ranked the random letter as second right off the bat, unfortunately still picking what it was trained on, but close! # Takeaway Overall this paper wasn’t too impressive after previously reading the papers on gpt. It did break the state of the art at the time compared to RNNs, but it still doesn’t seem to have a future. I don’t think character-level language models have too much promise compared to word-level ones, it does have more flexibility but also requires substantially more training. It did have a good summary of the field of RNNs in the related work section, though, so I may come back to it for that. # Other research I need to do more research into truncated backpropagation through time, sinusoidal timing signals, auxilary losses, and dynamic evaluation (which sounds interesting, a constantly training model maybe?)."
  },
  {
    "objectID": "posts/generative-pretrained-transformer/index.html",
    "href": "posts/generative-pretrained-transformer/index.html",
    "title": "Day 7 - Improving Language Understanding by Generative Pre-Training",
    "section": "",
    "text": "Summary\nThis is the GPT-1 paper, possibly one of the most influential papers of all time. This presented what would later change the world as ChatGPT! It is a Transformer that uses unsupervised pretraining to learn how to understand sentences beforehand, resulting in less training time when they fine-tune it on more specific tasks. This also means there is less need for labelled data to train a model, since any data can be used in an unsupervised way. The actual architecture of the model is a normal Transformer that is first pretrained on non-labelled data, BookCorpus in this case (thousands of unpublished books). This unique dataset allows it to learn long-range information, since they are books not short passages. It is then fine-tuned on different data depending on the task. So for example question answering, the most famous example due to ChatGPT, is done with multiple choice. To do this, they took questions with several answers, and fed each one independently into the model, taking the softmax of the outputs to determine the most probable one. Another interesting thing is that they graphed the performance of the model based off the number of layers, showing that it would benefit from more layers but would overfit faster, and a graph of the number of batches/epochs, which showed that it would benefit from being trained longer. This means that with more data and more layers/training time, it could become much better, which is true as seen in ChatGPT.\n\n\nTakeaway\nUnsupervised pretraining looks like a great way to prevent overfitting, I wonder if it can be applied elsewhere. Maybe an approach that starts by training the first layer, then the second layer, then the third, and works it’s way up until the final layer would be a nice way to prevent overfitting in the final sensitive layers but work on the first few, but there would need to be loss functions for each individual set of layers. This also shows that data is extremely important, and why ChatGPT was trained on such an incredibly large amount, why it costs millions of dollars to train/run.\n\n\nOther research\nThere actually wasn’t much this time, which is a hopeful time. I used ChatGPT to help me understand the math (ironic), and it was mainly based off the Transformer which I already mostly understand. I would like to implement one from scratch, though, to fully get it. Multi-head attention is still a bit fuzzy, as well as the Q,K, and V matrices. One thing I would like to research further is layernorm vs batchnorm."
  },
  {
    "objectID": "posts/classifying-simple-data/index.html",
    "href": "posts/classifying-simple-data/index.html",
    "title": "Using a neural network to predict poisonous fruit",
    "section": "",
    "text": "FUTURE ME: this post was very bad, I’m leaving it up for historical reasons but don’t try to follow it!\nI recently watched an interesting video by Sebastian Lague where he classifies random data using a neural network from scratch. I’m not quite good enough at calculus to do all of that, but I think I can pull it off with PyTorch. I am going to try and initialize some data, then classify a line that divides the data. That will actually be the hardest part, as I am still a novice at data science.\n\nPlotting the data\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('_mpl-gallery')\n\n\ndef random_ans(x, is_above):\n    y = correct_ans(x)\n    if is_above:\n        return np.random.uniform(y, y + 15)\n    return np.random.uniform(y, y - 15)\n\n\ndef correct_ans(x):\n    return 0.5*x**2-5\n\n\nstart = -25\nstop = 25\nnum_points = 20\n\nblueX = np.linspace(start,stop,num_points)\nredX = np.linspace(start,stop,num_points)\n\nblueY = random_ans(blueX,True)\nredY = random_ans(redX,False)\nactualY = correct_ans(blueX)\n# plot\nfig, ax = plt.subplots()\nax.scatter(blueX, blueY, c='blue')\nax.scatter(redX, redY, c='red')\nax.plot(blueX, actualY, linewidth=2.0)\n\nax.set(xlim=(start, stop), xticks=np.arange(start, stop,5),\n           ylim=(np.min(redY), np.max(blueY)), yticks=np.arange(np.min(redY), np.max(blueY),10))\nplt.show()\n\n\n\n\n\n\nthat seems to have made them too close to the line. I want them to be spread out evenly, like the video, so I will just generate random numbers then assign them based on whether they are above or below.\n\ndef classify(x,y):\n    return [(blue,x[idx]) for idx,blue in enumerate(y) if blue &gt; correct_ans(x[idx])], [(red,x[idx]) for idx,red in enumerate(y) if red &lt; correct_ans(x[idx])]\n\n\nstart = -25\nstop = 25\nnum_points = 500\n\nx = np.random.randint(start,stop,num_points)\ny = np.random.randint(start,stop,num_points)\nblue,red = classify(x,y)\nblueY,blueX = zip(*blue)\nredY, redX = zip(*red)\nactualX = np.linspace(start,stop,num_points)\nactualY = correct_ans(actualX)\n# plot\nfig, ax = plt.subplots()\nax.scatter(blueX, blueY, c='blue')\nax.scatter(redX, redY, c='red')\nax.plot(actualX,actualY, linewidth=2.0)\nax.set(xlim=(start, stop), xticks=np.arange(start, stop,5),\n           ylim=(start, stop), yticks=np.arange(start, stop,5))\nplt.show()\n\n\n\n\n\nIf I’m being honest, the reason that wasn’t commented is because I barely understand it. I spent an hour trying to make those functions work… Still trying to learn numpy. So just look up the functions yourselves if you want to see what they do, it was mostly ChatGPT’s work.\n\n\n\nOnto the model! Read the math classifier if you haven’t already, it should explain most of what is coming\n\nimport torch\nimport torch.nn as nn\n\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = nn.Linear(2, 64)  # Input size: 2 (x and y), Output size: 64\n        self.linear2 = nn.Linear(64, 1)  # Input size: 64, Output size: 1\n        self.relu = nn.ReLU()\n\n    def forward(self, xy):\n        # Apply the first linear layer followed by the ReLU activation\n        output = self.relu(self.linear1(xy))\n\n        # Apply the second linear layer\n        output = self.linear2(output)\n\n        return nn.functional.normalize(output)\n\n\n\nNow we need a way to display all the predicted values for the graph. I am going to use a PILImage, and set each pixel to either blue or red according to the model’s predictions. There may be a simpler way, but this seems fun.\n\nfrom PIL import Image\noutput_image = Image.new('RGB', (100, 100))\n# Generate x and y coordinate arrays\nx = np.arange(1, 101)\ny = np.arange(1, 101)\n\n# Use meshgrid to create 2D arrays for every combination\nX, Y = np.meshgrid(x, y)\n\n# Flatten the 2D arrays to get the final x and y coordinate arrays\nx_coords = torch.from_numpy(X.flatten())\ny_coords = torch.from_numpy(Y.flatten()).to(torch.float32)\n\n# Stack 'x' and 'y' along the last dimension to create a single tensor with shape (batch_size, 2)\nxy = torch.stack((x_coords, y_coords), dim=-1)\n\nnet = Net()\npreds = net(xy)\nfor row in range(100):\n    for col in range(100):\n        if preds[row*col] &gt; 0:\n            # Set the pixel to blue (255, 0, 0)\n            output_image.putpixel((col, row), (0, 0, 255))\n        else:\n            # Set the pixel to red (0, 0, 255)\n            output_image.putpixel((col, row), (255, 0, 0))\nplt.imshow(output_image)\nplt.axis('off')\nplt.show()\n\n\n\n\n\n# Seperate into function\ndef visualize_preds(net):\n    preds = net(xy)\n    for row in range(100):\n        for col in range(100):\n            if preds[row*col] &gt; 0:\n                # Set the pixel to blue (255, 0, 0)\n                output_image.putpixel((col, row), (0, 0, 255))\n            else:\n                # Set the pixel to red (0, 0, 255)\n                output_image.putpixel((col, row), (255, 0, 0))\n    plt.imshow(output_image)\n    plt.axis('off')\n    plt.show()\n\n\nvisualize_preds(net)\n\n\n\n\n\n\nOk, there is the output of the image. Let’s try training the model, to see if we can get a better output that looks more like the function.\n\nDataset initilization\n\nxy.shape\n\ntorch.Size([10000, 2])\n\n\n\ndef correct_ans_tensor(x,y):\n    return 0.5*x**2-5 &lt; y\n\n\ncorrectValues = correct_ans_tensor(x_coords,y_coords)\ncorrectValues.shape\ncorrectValues[0]\n\ntensor(True)\n\n\n\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\ncorrectValues = correctValues.float()\ndataset = torch.utils.data.TensorDataset(xy, correctValues)\ndata_loader = torch.utils.data.DataLoader(dataset, batch_size=64)\n\n\nfor epoch in range(10):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(data_loader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0], data[1]\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs.squeeze(), labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 100 == 99:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n\nprint('Finished Training')\n\n[1,   100] loss: 1.040\n[2,   100] loss: 1.040\n[3,   100] loss: 1.040\n[4,   100] loss: 1.040\n[5,   100] loss: 1.040\n[6,   100] loss: 1.040\n[7,   100] loss: 1.040\n[8,   100] loss: 1.040\n[9,   100] loss: 1.040\n[10,   100] loss: 1.040\nFinished Training\n\n\n\nnet(torch.tensor([[0., -2.], [3., 0.]]))\n\ntensor([[-1.],\n        [ 1.]], grad_fn=&lt;DivBackward0&gt;)\n\n\n\nvisualize_preds(net)\n\n\n\n\n\n\n\nOk, something went wrong here. It seems to be outputting roughly the same thing, so either my training went wrong or my image output is wrong\n\n# using pyplotlib to check\nstart = -25\nstop = 25\nnum_points = 500\n\nx = torch.from_numpy(np.random.randint(start,stop,num_points))\ny = torch.from_numpy(np.random.randint(start,stop,num_points))\nxy = torch.stack((x, y), dim=-1).float()\npredictions = net(xy)\nblue, red = [(blue,x[idx]) for idx,blue in enumerate(y) if 1. == predictions[idx]], [(red,x[idx]) for idx,red in enumerate(y) if -1. == predictions[idx]]\nblueY,blueX = zip(*blue)\nredY, redX = zip(*red)\nactualX = np.linspace(start,stop,num_points)\nactualY = correct_ans(actualX)\n# plot\nfig, ax = plt.subplots()\nax.scatter(blueX, blueY, c='blue')\nax.scatter(redX, redY, c='red')\nax.plot(actualX,actualY, linewidth=2.0)\nax.set(xlim=(start, stop), xticks=np.arange(start, stop,5),\n           ylim=(start, stop), yticks=np.arange(start, stop,5))\nplt.show()\n\n\n\n\n\n\nHmm, that didn’t work too well. Maybe there’s an issue with the training data? I’ll try doing it with all the points instead\n\ncorrectValues = correct_ans_tensor(x_coords,y_coords)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\ncorrectValues = correctValues.float()\ndataset = torch.utils.data.TensorDataset(xy, correctValues)\ndata_loader = torch.utils.data.DataLoader(dataset, batch_size=64)\n\nAssertionError: Size mismatch between tensors\n\n\n\nxy.shape\n\ntorch.Size([500, 2])\n\n\n\ncorrectValues.shape\n\ntorch.Size([10000])\n\n\n\ncorrectValues = correct_ans_tensor(x,y) # corrected to x,y\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\ncorrectValues = correctValues.float()\ndataset = torch.utils.data.TensorDataset(xy, correctValues)\ndata_loader = torch.utils.data.DataLoader(dataset, batch_size=64)\n\n\nfor epoch in range(100):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(data_loader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0], data[1]\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs.squeeze(), labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 16 == 1:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n\nprint('Finished Training')\n\n[1,     2] loss: 0.024\n[2,     2] loss: 0.024\n[3,     2] loss: 0.024\n[4,     2] loss: 0.024\n[5,     2] loss: 0.024\n[6,     2] loss: 0.024\n[7,     2] loss: 0.024\n[8,     2] loss: 0.024\n[9,     2] loss: 0.024\n[10,     2] loss: 0.024\n[11,     2] loss: 0.024\n[12,     2] loss: 0.024\n[13,     2] loss: 0.024\n[14,     2] loss: 0.024\n[15,     2] loss: 0.024\n[16,     2] loss: 0.024\n[17,     2] loss: 0.024\n[18,     2] loss: 0.024\n[19,     2] loss: 0.024\n[20,     2] loss: 0.024\n[21,     2] loss: 0.024\n[22,     2] loss: 0.024\n[23,     2] loss: 0.024\n[24,     2] loss: 0.024\n[25,     2] loss: 0.024\n[26,     2] loss: 0.024\n[27,     2] loss: 0.024\n[28,     2] loss: 0.024\n[29,     2] loss: 0.024\n[30,     2] loss: 0.024\n[31,     2] loss: 0.024\n[32,     2] loss: 0.024\n[33,     2] loss: 0.024\n[34,     2] loss: 0.024\n[35,     2] loss: 0.024\n[36,     2] loss: 0.024\n[37,     2] loss: 0.024\n[38,     2] loss: 0.024\n[39,     2] loss: 0.024\n[40,     2] loss: 0.024\n[41,     2] loss: 0.024\n[42,     2] loss: 0.024\n[43,     2] loss: 0.024\n[44,     2] loss: 0.024\n[45,     2] loss: 0.024\n[46,     2] loss: 0.024\n[47,     2] loss: 0.024\n[48,     2] loss: 0.024\n[49,     2] loss: 0.024\n[50,     2] loss: 0.024\n[51,     2] loss: 0.024\n[52,     2] loss: 0.024\n[53,     2] loss: 0.024\n[54,     2] loss: 0.024\n[55,     2] loss: 0.024\n[56,     2] loss: 0.024\n[57,     2] loss: 0.024\n[58,     2] loss: 0.024\n[59,     2] loss: 0.024\n[60,     2] loss: 0.024\n[61,     2] loss: 0.024\n[62,     2] loss: 0.024\n[63,     2] loss: 0.024\n[64,     2] loss: 0.024\n[65,     2] loss: 0.024\n[66,     2] loss: 0.024\n[67,     2] loss: 0.024\n[68,     2] loss: 0.024\n[69,     2] loss: 0.024\n[70,     2] loss: 0.024\n[71,     2] loss: 0.024\n[72,     2] loss: 0.024\n[73,     2] loss: 0.024\n[74,     2] loss: 0.024\n[75,     2] loss: 0.024\n[76,     2] loss: 0.024\n[77,     2] loss: 0.024\n[78,     2] loss: 0.024\n[79,     2] loss: 0.024\n[80,     2] loss: 0.024\n[81,     2] loss: 0.024\n[82,     2] loss: 0.024\n[83,     2] loss: 0.024\n[84,     2] loss: 0.024\n[85,     2] loss: 0.024\n[86,     2] loss: 0.024\n[87,     2] loss: 0.024\n[88,     2] loss: 0.024\n[89,     2] loss: 0.024\n[90,     2] loss: 0.024\n[91,     2] loss: 0.024\n[92,     2] loss: 0.024\n[93,     2] loss: 0.024\n[94,     2] loss: 0.024\n[95,     2] loss: 0.024\n[96,     2] loss: 0.024\n[97,     2] loss: 0.024\n[98,     2] loss: 0.024\n[99,     2] loss: 0.024\n[100,     2] loss: 0.024\nFinished Training\n\n\n\n# using pyplotlib to check\nstart = -25\nstop = 25\nnum_points = 500\n\nx = torch.from_numpy(np.random.randint(start,stop,num_points))\ny = torch.from_numpy(np.random.randint(start,stop,num_points))\nxy = torch.stack((x, y), dim=-1).float()\npredictions = net(xy)\nblue, red = [(blue,x[idx]) for idx,blue in enumerate(y) if 1. == predictions[idx]], [(red,x[idx]) for idx,red in enumerate(y) if -1. == predictions[idx]]\nblueY,blueX = zip(*blue)\nredY, redX = zip(*red)\nactualX = np.linspace(start,stop,num_points)\nactualY = correct_ans(actualX)\n# plot\nfig, ax = plt.subplots()\nax.scatter(blueX, blueY, c='blue')\nax.scatter(redX, redY, c='red')\nax.plot(actualX,actualY, linewidth=2.0)\nax.set(xlim=(start, stop), xticks=np.arange(start, stop,5),\n           ylim=(start, stop), yticks=np.arange(start, stop,5))\nplt.show()\n\n\n\n\n\n\nOk, something is 100% wrong with my model. Maybe adding more layers will do the trick.\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = nn.Linear(2, 64)  # Input size: 2 (x and y), Output size: 64\n        self.linear2 = nn.Linear(64, 128)  # Input size: 64, Output size: 128\n        self.linear3 = nn.Linear(128, 1)  # Input size: 128, Output size: 1\n        self.relu = nn.ReLU()\n\n    def forward(self, xy):\n        # Apply the first linear layer followed by the ReLU activation\n        output = self.relu(self.linear1(xy))\n\n        # Apply the second linear layer followed by the ReLU activation\n        output = self.relu(self.linear2(output))\n\n        # Apply the third linear layer\n        output = self.linear3(output)\n\n        return nn.functional.normalize(output)\n\nnet = Net()\n\n\nfor epoch in range(100):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(data_loader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0], data[1]\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs.squeeze(), labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 128 == 8:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n\nprint('Finished Training')\n\nFinished Training\n\n\n\n# using pyplotlib to check\nstart = -25\nstop = 25\nnum_points = 500\n\nx = torch.from_numpy(np.random.randint(start,stop,num_points))\ny = torch.from_numpy(np.random.randint(start,stop,num_points))\nxy = torch.stack((x, y), dim=-1).float()\npredictions = net(xy)\nblue, red = [(blue,x[idx]) for idx,blue in enumerate(y) if 1. == predictions[idx]], [(red,x[idx]) for idx,red in enumerate(y) if -1. == predictions[idx]]\nblueY,blueX = zip(*blue)\nredY, redX = zip(*red)\nactualX = np.linspace(start,stop,num_points)\nactualY = correct_ans(actualX)\n# plot\nfig, ax = plt.subplots()\nax.scatter(blueX, blueY, c='blue')\nax.scatter(redX, redY, c='red')\nax.plot(actualX,actualY, linewidth=2.0)\nax.set(xlim=(start, stop), xticks=np.arange(start, stop,5),\n           ylim=(start, stop), yticks=np.arange(start, stop,5))\nplt.show()\n\n\n\n\n\n\nMuch more promising! It seems like the problem is that it doesn’t have enough layers, which is odd because it seems like an easy function, but I guess not.\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = nn.Linear(2, 256)  # Input size: 2 (x and y), Output size: 256\n        self.linear2 = nn.Linear(256, 128)  # Input size: 256, Output size: 128\n        self.linear3 = nn.Linear(128, 64)  # Input size: 128, Output size: 64\n        self.linear4 = nn.Linear(64, 1)  # Input size: 64, Output size: 1\n        self.relu = nn.ReLU()\n\n    def forward(self, xy):\n        # Apply the first linear layer followed by the ReLU activation\n        output = self.relu(self.linear1(xy))\n\n        # Apply the second linear layer followed by the ReLU activation\n        output = self.relu(self.linear2(output))\n\n        # Apply the third linear layer followed by the ReLU activation\n        output = self.relu(self.linear3(output))\n\n        # Apply the fourth linear layer\n        output = self.linear4(output)\n\n        return nn.functional.normalize(output)\n\nnet = Net()\n\n\nfor epoch in range(100):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(data_loader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0], data[1]\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs.squeeze(), labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 128 == 8:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n\nprint('Finished Training')\n\nFinished Training\n\n\n\n# using pyplotlib to check\nstart = -25\nstop = 25\nnum_points = 500\n\nx = torch.from_numpy(np.random.randint(start,stop,num_points))\ny = torch.from_numpy(np.random.randint(start,stop,num_points))\nxy = torch.stack((x, y), dim=-1).float()\npredictions = net(xy)\nblue, red = [(blue,x[idx]) for idx,blue in enumerate(y) if 1. == predictions[idx]], [(red,x[idx]) for idx,red in enumerate(y) if -1. == predictions[idx]]\nblueY,blueX = zip(*blue)\nredY, redX = zip(*red)\nactualX = np.linspace(start,stop,num_points)\nactualY = correct_ans(actualX)\n# plot\nfig, ax = plt.subplots()\nax.scatter(blueX, blueY, c='blue')\nax.scatter(redX, redY, c='red')\nax.plot(actualX,actualY, linewidth=2.0)\nax.set(xlim=(start, stop), xticks=np.arange(start, stop,5),\n           ylim=(start, stop), yticks=np.arange(start, stop,5))\nplt.show()\n\n\n\n\n\n\noh… a bit too far. Well, I guess this was a good introduction to more PyTorch, but I am going to have to end here. I’ve been tearing my hair out for hours, and I need to read the daily scientific paper!"
  },
  {
    "objectID": "posts/a-gentle-introduction-to-rnns/index.html",
    "href": "posts/a-gentle-introduction-to-rnns/index.html",
    "title": "Day 11 - Recurrent Neural Networks (RNNs): A gentle Introduction and Overview",
    "section": "",
    "text": "Summary\nThis paper explained several things conceptually, from RNNs to Transformers. This was like the matrix calculus paper, an explanation and not anything new. There was a lot of math, but I actually tried and somewhat succeeded to understand it. I enjoyed it a lot, it presented several things I didn’t know about. They first described traditional RNNs, which are basically feed-forward networks but they pass in the weights to the previous layer, allowing for information from past layers to be given to the next ones, basically making them recursive. The way of taking the derivate of this is quite complex, but basically it involves taking the partial derivative of each layer and inputing that for the recursion of each one. This comes with several problems, like vanishing and exploding gradients. There are several ways to fix this, one being long short-term memory, using some weird gates outside of the network to prevent the issues. I don’t really get how this works, so I am going to read some of the papers cited here, like the one on StarCraft with LSTMs. There is also bidirectional recurrent neural nets, which are used when you fill in a word in the middle of the sentence, so you need the text both ahead and behind the word. You basically use two seperate recurrent neural nets, one with the normal net and one with the words in reverse, taking the words from back to the blank word.\nThen there are encoder-decoder architectures, basically encoding the input into a state and decoding the state. I didn’t get it too much from this paper, but I do have a previous understanding from video one of Jeremy Howard’s FastAI part 2 course, an intro to stable diffusion. But it seems to allow for encoding into a state that a neural net understands, and then decoding into an output that we understand. They also described attention and neural nets, but I already tried to describe that in my attention is all you need blog post. They did have some good resources that I will try to look into, though. Finally, there are pointer networks, which I didn’t get at all, so I have the paper that presented those on my to-read list for tomorrow’s paper.\n\n\nTakeaway\nRecurrent neural nets seem like a good extension of feed-forward networks, whereas I had previously considered them as extinct due to attention and transformers. It still seems like they could have uses elsewhere, though, and I hope to see them make a return in the future, as no one really understands the Q, K, and V matrices apparently while these are pretty easily understood. I did like all the resources presented in the paper, though, and I will 100% look into those at a later date. I don’t usually summarize other blog posts or books, which are the majority of what was presented, but we shall see.\n\n\nOther research\nplanar convex hulls, Delaunay triangulations, and the symmetric planar Travelling Salesman Problem. I have heard of the Travelling Salesman Problem before from a good Sebastian Lague video, but I don’t know what a symmetric planar one is. I would like to make a math notation cheat sheet at some point to help me, like unions and partial derivates and derivate rules, but it sounds like a lot of work and something like that probably already exists, so maybe I’ll try and find it instead. I would like to learn LateX at some point though."
  },
  {
    "objectID": "posts/pytorch/index.html",
    "href": "posts/pytorch/index.html",
    "title": "Day 13 - PyTorch: An Imperative Style, High-Performance Deep Learning Library",
    "section": "",
    "text": "I had an interest in this paper since making the autograd engine from micrograd, since I want to see how they did it. Pytorch was made in C++ to be faster, and is made as an alternative to the traditional compile-based dataflow graph libraries, but also isn’t a slow library. It uses things like custom caching tensor allocator to allow for dynamic eager execution, which makes code easier to write for the end user. This has led to the popularization of PyTorch as an alternative to libraries like TensorFlow. This paper actually wasn’t released until long after PyTorch was made, since it mentions being cited as the library of choice for many papers already. I use and enjoy PyTorch, so this was a good way to get a behind the scenes look, but it isn’t necessary if you just want to do Deep Learning or AI dev."
  },
  {
    "objectID": "posts/imagenet-classification-with-deep-convolutional-neural-networks/index.html",
    "href": "posts/imagenet-classification-with-deep-convolutional-neural-networks/index.html",
    "title": "ImageNet Classification with Deep Convolutional Neural Networks",
    "section": "",
    "text": "import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n\n\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\n\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)\n\n\n# plot an example of the data\nimport matplotlib.pyplot as plt\nplt.imshow(training_data.data[0], cmap='gray')\nplt.title('%i' % training_data.targets[0])\nplt.show()\n\n\n\n\n\nbatch_size = 64\n\n# Create data loaders.\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=True)\n\nfor X, y in test_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break\n\nShape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\nShape of y: torch.Size([64]) torch.int64\n\n\n\ndevice = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")\n\nUsing cuda device\n\n\n\n# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv_stack = nn.Sequential( # a convolution, then an activation function, then a maxpool\n            nn.Conv2d(1, 16, 5),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.conv_stack_2 = nn.Sequential( # a convolution, then an activation function, then a maxpool\n            nn.Conv2d(16, 32, 5),     \n            nn.ReLU(),                      \n            nn.MaxPool2d(2),                \n        )\n        self.out = nn.Linear(64, 512) # fully connected layer\n\n    def forward(self, x):\n        x = self.conv_stack(x)\n        x = self.conv_stack_2(x)\n        x = x.view(x.size(0), -1) # flatten the output to allow for a linear layer (lines up the data along 1d vector\n        output = self.out(x)\n        return output\n\nmodel = NeuralNetwork().to(device)\nprint(model)\n\nNeuralNetwork(\n  (conv_stack): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv_stack_2): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (out): Linear(in_features=64, out_features=512, bias=True)\n)\n\n\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader): #X,y is images,labels\n        X, y = X.to(device), y.to(device)\n #X,y is images,labels\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        #if batch % 100 == 0:\n         #   loss, current = loss.item(), (batch + 1) * len(X)\n          #  print(f\"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]\")\n\n\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \\n\")\n\n\nepochs = 2\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    #test(test_dataloader, model, loss_fn)\nprint(\"Done!\")\n\nEpoch 1\n-------------------------------\n\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (64x512 and 64x512)"
  },
  {
    "objectID": "posts/imagenet-classification-with-deep-convolutional-neural-networks/index.html#first-portion-learning-via-just-fashionmnist.-skip-this-i-am-just-including-it-to-show-beginners-that-i-too-dont-know-what-im-doing",
    "href": "posts/imagenet-classification-with-deep-convolutional-neural-networks/index.html#first-portion-learning-via-just-fashionmnist.-skip-this-i-am-just-including-it-to-show-beginners-that-i-too-dont-know-what-im-doing",
    "title": "ImageNet Classification with Deep Convolutional Neural Networks",
    "section": "",
    "text": "import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n\n\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\n\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)\n\n\n# plot an example of the data\nimport matplotlib.pyplot as plt\nplt.imshow(training_data.data[0], cmap='gray')\nplt.title('%i' % training_data.targets[0])\nplt.show()\n\n\n\n\n\nbatch_size = 64\n\n# Create data loaders.\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=True)\n\nfor X, y in test_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break\n\nShape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\nShape of y: torch.Size([64]) torch.int64\n\n\n\ndevice = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")\n\nUsing cuda device\n\n\n\n# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv_stack = nn.Sequential( # a convolution, then an activation function, then a maxpool\n            nn.Conv2d(1, 16, 5),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.conv_stack_2 = nn.Sequential( # a convolution, then an activation function, then a maxpool\n            nn.Conv2d(16, 32, 5),     \n            nn.ReLU(),                      \n            nn.MaxPool2d(2),                \n        )\n        self.out = nn.Linear(64, 512) # fully connected layer\n\n    def forward(self, x):\n        x = self.conv_stack(x)\n        x = self.conv_stack_2(x)\n        x = x.view(x.size(0), -1) # flatten the output to allow for a linear layer (lines up the data along 1d vector\n        output = self.out(x)\n        return output\n\nmodel = NeuralNetwork().to(device)\nprint(model)\n\nNeuralNetwork(\n  (conv_stack): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv_stack_2): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (out): Linear(in_features=64, out_features=512, bias=True)\n)\n\n\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader): #X,y is images,labels\n        X, y = X.to(device), y.to(device)\n #X,y is images,labels\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        #if batch % 100 == 0:\n         #   loss, current = loss.item(), (batch + 1) * len(X)\n          #  print(f\"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]\")\n\n\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \\n\")\n\n\nepochs = 2\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    #test(test_dataloader, model, loss_fn)\nprint(\"Done!\")\n\nEpoch 1\n-------------------------------\n\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (64x512 and 64x512)"
  },
  {
    "objectID": "posts/the-matrix-calculus-for-deep-learning/index.html",
    "href": "posts/the-matrix-calculus-for-deep-learning/index.html",
    "title": "Day 5 - The Matrix Calculus You Need For Deep Learning",
    "section": "",
    "text": "Summary\nThis paper is meant to educate people about multi-variable calculus and deep learning. Overall the most useful paper I’ve read so far. It told me about the Jacobian matrix, derivative rules, and more. I didn’t understand all of it, but it told me some really interesting stuff. Overall though, I will have to revisit it, as it’s a 30 page paper and I really only understood the first few pages. Great read!\n\n\nTakeaway\nI am getting a paperback calculus book right now, as I really need to freshen up my math skills. Once school starts back up in Augest, I’m going to dedicate large portions of my time to the math side, and hopefully I’ll get some trig from my classes.\n\n\nOther research\nI don’t know if there are other papers like this, but I will start reading Calculus and Linear Algebra textbooks. This should help me understand the proofs and math side more."
  },
  {
    "objectID": "posts/pytorch-function-classifier/index.html",
    "href": "posts/pytorch-function-classifier/index.html",
    "title": "Math function classifier with Pytorch",
    "section": "",
    "text": "FUTURE ME: This project was kinda a failure, I wouldn’t try to follow it The goal of this project is to be able to type in a math function and have it be graphed, then have a Neural Net try to predict the function with no knowledge of what it is. This is to help me learn Pytorch, as well as graphing tools like matplot.\n\nHelper functions\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt # I had an error and had to also install ipywidgets in case you run into that\nplt.style.use('_mpl-gallery')\n\n\ndef plot_func(func,num_points=2000,start=-5,stop=5):\n    x = np.linspace(start,stop,num_points) # returns 2000 points evenly spaced from 1-100\n    y = func(x)\n    # plot\n    fig, ax = plt.subplots()\n\n    ax.plot(x, y, linewidth=2.0)\n\n    ax.set(xlim=(start, stop), xticks=np.arange(start, stop),\n           ylim=(start, stop), yticks=np.arange(start, stop))\n    return x,y,ax \n\n\ndef sin(x):\n    return np.sin(x) \n\n\nx,y,ax = plot_func(sin) # plot a function and get 2000 numbers from -5 to 5 with their corrosponding y values (also the axis to plot the predicted function on\nax.plot(x,x**2)\nplt.show()\n\n\n\n\n\n\nPredictor, with only tensors and autoback\n\nIn order to predict the function, we need a series of steps:\n\nInitialize random values.\nWe are going to use an n-series polynomial. So we can pass in the number of polynomials, for example 3, and it will make a trinomial. So the predictor function would be ax^2 + bx + c, and abc would be the three parameters. I will write a function to do this now.\n\n\ndef make_params(num_params=4):\n    return torch.randn(num_params, requires_grad=True) # requires grad is so we can do backpropogation later\n\n\ndef pred_func(params,x):\n    y = torch.zeros_like(x)\n    for (idx,param) in enumerate(params):\n        y += param * x ** idx\n    return y\n\n\n# test call\nparams = make_params()\nprint(params)\npreds = pred_func(params,torch.from_numpy(x)) # convert numpy array to tensor\n#ax.plot(x, preds.detach().numpy(), linewidth=2.0)\n#plt.show()\nstart = -5\nstop = 5\nfig, ax = plt.subplots()\n\nax.plot(x, preds.detach().numpy(), linewidth=2.0)\n\nax.set(xlim=(start, stop), xticks=np.arange(start, stop),\n       ylim=(start, stop), yticks=np.arange(start, stop))\nplt.show()\n\ntensor([ 0.6242, -0.1516,  0.1190, -0.2926], requires_grad=True)\n\n\n\n\n\n\n\n\nNow we have our prediction function, what about training?\nThe only thing that makes a neural network special is for it’s ability to learn, so we need to implement backpropogation to teach it.\n\ndef update_params(params,learning_rate):\n    with torch.no_grad():\n        for param in params:\n            param -= learning_rate * param.grad\n            param.grad = None # manually zero the grad after updating weights\n\n\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nlearning_rate = 1e-6\ntorch.set_default_tensor_type(torch.FloatTensor)\nparams = make_params()\nx = torch.linspace(start, stop, steps=2000)\ny = torch.sin(x)\noptimizer = optim.SGD([params], lr=learning_rate)\nfor t in range(5000):\n    # Forward pass: compute predicted y using operations on Tensors.\n    preds = pred_func(params,x)\n\n    # Compute and print loss using operations on Tensors.\n    # Now loss is a Tensor of shape (1,)\n    # loss.item() gets the scalar value held in the loss.\n    loss = F.mse_loss(preds, y) #(preds - y).pow(2).sum()\n    if t % 100 == 99:\n        print(t, loss.item())\n\n    # Use autograd to compute the backward pass. This call will compute the\n    # gradient of loss with respect to all Tensors with requires_grad=True.\n    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n    # the gradient of the loss with respect to a, b, c, d respectively.\n    optimizer.zero_grad()  # Zero the gradients before computing new ones\n    loss.backward()       # Compute gradients\n    optimizer.step()      # Update parameters using the optimizer\n\nfig, ax = plt.subplots()\n\nax.plot(x, preds.detach().numpy(), linewidth=2.0)\n\nax.set(xlim=(start, stop), xticks=np.arange(start, stop),\n       ylim=(start, stop), yticks=np.arange(start, stop))\nplt.show()\n\n99 1897.98828125\n199 924.3157958984375\n299 521.1401977539062\n399 350.1914978027344\n499 273.97296142578125\n599 236.58543395996094\n699 215.29432678222656\n799 200.8443145751953\n899 189.45916748046875\n999 179.59019470214844\n1099 170.5946044921875\n1199 162.19876098632812\n1299 154.27919006347656\n1399 146.77444458007812\n1499 139.64865112304688\n1599 132.87693786621094\n1699 126.43931579589844\n1799 120.31834411621094\n1899 114.4981460571289\n1999 108.96375274658203\n2099 103.70096588134766\n2199 98.69640350341797\n2299 93.93749237060547\n2399 89.4121322631836\n2499 85.10885620117188\n2599 81.01679992675781\n2699 77.12552642822266\n2799 73.42524719238281\n2899 69.90657043457031\n2999 66.560546875\n3099 63.37876510620117\n3199 60.35309600830078\n3299 57.47591018676758\n3399 54.73991394042969\n3499 52.1381721496582\n3599 49.66405487060547\n3699 47.31141662597656\n3799 45.074214935302734\n3899 42.946773529052734\n3999 40.92372512817383\n4099 38.99995803833008\n4199 37.17057418823242\n4299 35.43095397949219\n4399 33.77667999267578\n4499 32.203582763671875\n4599 30.707674026489258\n4699 29.2851505279541\n4799 27.932395935058594\n4899 26.646024703979492\n4999 25.422761917114258\n\n\n\n\n\n\n\nAfter getting it working with much struggle, we can now move onto moving everything into a class to make things much easier and more readable\n\nclass Net(torch.nn.Module):\n    def __init__(self, num_params=3):\n        super().__init__()\n        self.num_params = num_params\n        self.num_params = num_params\n        self.params = torch.nn.Parameter(torch.randn(num_params) * 0.01)  # Manually initialize with small values\n    def forward(self, x):\n        y = torch.zeros_like(x)\n        for idx in range(self.num_params):\n            y += self.params[idx] * torch.pow(x, idx)\n        return y\n\n\n# Assuming x and y are your input data and target values respectively\nx = torch.linspace(-5, 5, 2000)\ny = torch.sin(x)\n\nx = x.unsqueeze(1)  # Add a dimension to x to make it a 2D tensor (2000, 1)\ny = y.unsqueeze(1)  # Add a dimension to y to make it a 2D tensor (2000, 1)\n\n\n# Define the model, loss function, and optimizer\nmodel = Net()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n\nfor t in range(200):\n    # Forward pass: Compute predicted y by passing x to the model\n    y_pred = model(x)\n\n    # Compute and print loss\n    loss = criterion(y_pred, y)\n    if t % 100 == 99:\n        print(t, loss.item())\n\n    # Zero gradients, perform a backward pass, and update the weights.\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n99 3.1718812266429933e+33\n199 inf\n\n\n\n\nAfter a couple hours of work, it looks like this isn’t going to work. I got it to work above, but I have no idea why the gradients are exploding here. I may try and come back later, but I actually still think this taught me a lot, as I now know how models work. I am going to go and try to make an actual model now."
  },
  {
    "objectID": "posts/gpt-three/index.html",
    "href": "posts/gpt-three/index.html",
    "title": "Day 9 - Language Models are Few-Shot Learners",
    "section": "",
    "text": "Summary\nThis is the GPT-3 paper, an expansion of Day 8’s paper on GPT-2. It is what happens when you take parameters to the extreme. At the largest model, they had 175 billion parameters, and yet it only took a couple cents for inference (training costs were a whole different story). The novel idea they presented was few-shot or zero-shot learning, where you present the model with a few examples of what you want it to do (without updating the weights) and it “learns” from those, just in it’s context window. This is shown in ChatGPT, where you describe the task and include an example (one-shot learning). This resulted in a model that could match some state of the art models without fine-tuning, which is incredible, since it means there is no need for large fine-tuning datasets. They did preprocess some of the Common Crawl datasets content, as it is just a collection of the Internet, not filtering for high-quality data. They reduced it from dozens of TB of data to only 50 GB. The only architectural difference besides this and GPT-2 is that it uses alternating dense and locally banded sparse attention patterns, which I do not understand at all. I will have to do more research on the Sparse Transformer paper!\nThe social impacts of this model were also discussed. The model presented a lot of the biases shown on the Internet. An approach to correct this could be filtering text beforehand for sexist or racist content, but we need to find a way to fix this.\n\n\nTakeaway\nI think the power of a good dataset is greatly underestimated, and I think OpenAI understands that. Instead of using CommonCrawl, they filtered it into a more high-quality dataset, resulting in better training. I think this could go even further, only including high quality data like books, scientific papers, Wikepedia, and maybe Github (filtered). There is a paper called Textbooks are all you need, which I plan to read, that trains incredibly small models that do well due to the quality of the data they are trained on. If we had 50 GB of good quality data, I think we could get GPT 5 with the same or even less parameters than GPT 3. We could also take a look at all of the tasks GPT 3 is bad on and include small datasets specifically made for them. A math and reversed word dataset would be great for helping GPT understand how the fundamental tokens work. Or they could use a MoE approach, which may be what GPT-4 uses, and train a bunch of smaller language models that are only good at, say, math. This would require training many different models, but it would also result in better performance with less energy usage.\n\n\nOther research\nAlternating dense and locally banded sparse attention patterns, beam search, F1 similarity score vs BLEU vs exact match, autoregressive vs bidirectional models, temperature and top p."
  },
  {
    "objectID": "posts/100-papers-100-days/index.html",
    "href": "posts/100-papers-100-days/index.html",
    "title": "100 Papers in 100 Days",
    "section": "",
    "text": "A paper a day for 100 days (7/17-10/25)\nThis is a challenge I am setting in order to keep up with the latest research. New models and papers are coming out multiple times per day, and I feel like I have been falling behind. This challenge will hopefully keep me motivated to read a paper every single day, or two for a day if I miss one for any reason. By the end I hope to have a deeper understanding of the Machine Learning world and the Academia world, and hope to be able to implement some papers on my own. I will publish a summary of every paper I read here, and it should allow me to stay accountable. The first one is already up!"
  },
  {
    "objectID": "posts/making-a-blog/index.html",
    "href": "posts/making-a-blog/index.html",
    "title": "Getting started with a Quarto blog",
    "section": "",
    "text": "The best way to stay motivated during your journey into learning to code (or anything really) is to tell people about it. Keep yourself accountable. Editing youtube videos may be too much for you (like it is for me) so I recommend blogging. Not just a simple Medium blog, though, although if that’s all you need then go right ahead. This is blogging specifically for coding, so you can show off the actual code and its results, allowing anyone to see how you did what you did.\nIf you need convincing, take a look at this article by Rachel Thomas\nNow, onto how to do so. This is assuming you have a personal computer that you want to run your blog on, with no experience or coding tools installed.\nWe are going to use Jupyter Labs with Quarto for the actual articles.\n\nInstalling Git\nGit is a version control system, so that if your computer breaks you have all of your code backed up to the cloud. We are going to use it with Github. You should already have it if you use Linux, but if you use Windows you are going to have to set up Windows Subsystem for Linux. You can run normal Windows with Git for Windows if you really want to, but most of this tutorial won’t work for you, and you will have a lot of troubles later on. To install WSL, go to 31:29 on Lesson 2 of the FastAI course, they have a good tutorial on how to do it.\n\n\nInstalling Python with Mamba\nWe are going to use fastsetup, an easy way to get your computer set up for programming with Python. The setup-conda.sh file shown here is what we will use to download everything. To get some experience with Git, try cloning the repository on your own. For some help, here are the commands:\nsudo apt update && sudo apt -y install git\ngit clone https://github.com/fastai/fastsetup.git\ncd fastsetup\nsudo ./setup-conda.sh\n# optionally, for installing the FastAI library and other things like PyTorch\nmamba install -c fastchan fastai\nIf you want the full install for Ubuntu Linux, you can also read the README of the repository.\n\nInstalling Jupyter Labs and Quarto\nmamba install -c conda-forge jupyterlab To install Quarto, go to their download page and download the correct version and run it.\n\n\n\nSetting up the blog\nGo to the terminal, and navigate to the location you want to put the Blog in via cd. I’m simply in the Documents folder. Then, to make a new Quarto project, run quarto create-project Blog --type website:blog. Now you should see a Blog folder if you run ls. To see the blog itself, run quarto preview Blog and it should pop up in a new window. That terminal is now being used to run quarto, so open up another one and navigate to the Blog folder (go into it this time). Run the command jupyter lab to open up your IDE. You should now see the whole folder in the Jupyter Lab Development Environment. Here you can change some of the Quarto files, such as about.qmd, index.qmd, etc. I have the superhero theme set in `_quarto.yml’.\n\n\n\nJupyter Lab\n\n\nTo make it look a little bit better, we need to change some default settings. Go to the Plugins tab (the puzzle icon on the left sidebar) and search git. Download the jupyterlab git plugin. Also look up and install LSP (language server protocol) and quarto.\nTo change to dark mode, go to Settings in the top navbar, then Theme, then choose Dark. Now, you need to restart Jupyter Lab to make the plugins go into effect. Go to File, then Shut down at the bottom. Run the same commands as above to open Jupyter Lab back up. You should now see roughly the same screen shown above, without the two tabs.\n\n\nSetting up GitHub\nYou will need a Github account to back up the Blog. Go ahead and create one on their website, setting up a profile as usual. After, make a new repository called Blog (or whatever else). Do not add a README or license or anything yet.\nIn the JupyterLab main screen, make a new tab and use Terminal (shown in Other). In that, run the following commands, replacing information as needed:\ngit config ‒global user.email {your Github email}\ngit config user.name {your Github name}\ngit init -b main\ngit add .\ngit commit -m \"added blog files\"\ngit remote add origin https://github.com/{your profile name}/blog.git \ngit push ‒set-upstream origin main\nYou should now be able to add new files and commit them to Github from the sidebar. Now change some default settings with Git to make it easier to push your changes. Go to Advanced Settings Editor (Ctrl comma), then Git, then change simple staging flag to true and trigger push on commit to true.\n\n\nPublishing the Blog\nIf you just want it for yourself, you can stop the tutorial here and start editing. Use a Quarto guide online to do so. If you do want to publish it, there are two options. Well, there are many, but these are the top two in my opinion.\n\nThe simplest, publishing to Quarto Pub\nThis one is for people with no web development experience. Go to Quarto Pub, sign up, and choose a username. Now, go back to the terminal, navigate to the blog directory, and run quarto publish once you are ready for you blog to hit the world. It will ask you to put in some authentication information the first time, and then you are done!\n\n\nThe hard option, making your own website\nI won’t go too deep into this, as you should be experienced with Web Dev to do this option. I suggest using something like Vercel to deploy a simple static application with all of the prerendered files you get using quarto render.\n\n\n\nYou are done!\nIf you successfully made it through, please email me at jaxbulbrook@gmail.com and I will take a look at your blog! For ideas to post, I suggest doing a 100 days of X challenge (I am personally reading 100 papers in 100 days) or documenting your coding journey with weekly devlogs. Enjoy!"
  },
  {
    "objectID": "posts/deepface-facial-recognizer/index.html",
    "href": "posts/deepface-facial-recognizer/index.html",
    "title": "Day 6 - DeepFace: Closing the Gap to Human-Level Performance in Face Verification",
    "section": "",
    "text": "Summary\nThis paper presents Facebook’s state of the art at the time face classifier called DeepFace. It replaced traditional methods that both had less accuracy AND required more features to be labelled. This was unsupervised, with an almost human accuracy, leading to it being widely adapted. One interesting statistic was that on the Video Dataset, videos collected from Youtube (which can often be blurry), was used to test the model and it scored 91.4%, a 50% increase over the previous state of the art! It also runs at only 0.33 seconds per image on a single core of a CPU! Good read, there was a good amount of math and vocabulary I didn’t understand but I will do more research. I might have to move my papers around so I get the vocab before more state of the art stuff.\n\n\nTakeaway\nI want to experiment with 3d modelling of images, that looks interesting. Also would like to test out the facial recognition at some point, there’s a python library that can do it which looks cool.\n\n\nOther research\nThis paper had a ton of good resources I will have to come back to, especially for the history of facial recognition software. Some specifics I need to learn include a Siamese Network, SVMs, PCA, Linear Discriminant Analysis, LBP, Joint Bayesian Models, Delaunay triangulation, Cholesky decomposition, power CPD-kernels, and ordinary least squares."
  },
  {
    "objectID": "posts/convnext/index.html",
    "href": "posts/convnext/index.html",
    "title": "Day 4 - A ConvNet for the 2020s",
    "section": "",
    "text": "Summary\nThis paper is an attempt to combine the various state of the art results from various convnets over the years into one model. All have been done before, but never in the same model. This results in a higher performance model than ViT models (Vision Transformers), which were state of the art at the time. The reason they did this is because ViT models had a few major problems, like a quadratic context length for the image size, meaning it becomes memory intensive quite quickly. To implement the new ConvNeXt, they took Resnet as a base and added various techniques inspired by Swin Transformers. The techniques they used were as follows:\n1. Training optimizations such as AdamW optimizer, data augmentation techniques like Mixup, Cutmix, RandAugment, Random Erasing, and regularization scehemes like Stochastic Depth and Label Smoothing. I will have to research all of these topics more in depth. +2.7% 2. Macro design: The network as a whole - Changing stage compute ratio by changing the number of blocks in each stage to (3,3,9,3). The stage compute is how much computing power is dedicated to each stage, so stage 3 has 3x more. +0.6% - Changing stem to “Patchify” - the stem is how the input image is transformed. There is a careful consideration of how much data you really want, because too much is a lot of compute and too little is not enough data. This is done by a 7x7 convolution with stride 2 then a max pool, decreasing the input image by 4x. A patchify layer is a convolution that doesn’t overlap, in this case they did 4x4. +0.1% - Using groups and increasing model size - they use groups, which basically means using many convolutions that each only look at a small portion of the input data, and therefore need fewer parameters. They make many more groups, though, to offset for this loss of performance from only looking at some of the data. +1% - Using an inverted bottleneck design - I will have to look more into this, but here is my understanding as of right now: You take a 1x1 convolution to exapdn the number of input channels, using a small number of filters called the bottleneck width. They then do a depthwise convolution, adding a seperate filter to each input channel. Finally, they use a 1x1 convolution again the shrink the number of channels to the desired output size. I’m not sure how they are able to shrink it, though, so I’ll let you know later. +0.1% - Using a larger kernel size of 7x7, and putting it after the inverted bottleneck block so that the efficient 1x1 kernels do the heavy lifting while this is inefficient but now run on less data due to the inverted bottleneck shrink. +0 3. Micro design: Invidiaul layers - Replacing ReLU with GELU: ReLU just changes negative numbers to zero, while GELU smoothes them out move. This actually doesn’t change accuracy, though. +0 - Fewer activation functions - Transformers only use activation functions after a few blocks. Doing so in this results in +0.7%. - Fewer normalization layers - They reduce the number of BatchNorm layers by 2. +0.1% - Substituting BatchNorm with LayerNorm - Layer Normalization is much simpler, (and is added to my research list), resulting in +0.1%. - Seperate downsampling layers - a downsampling layer decreases the amount of pixels/resolution. This is achieved with a convolution with a stride higher than it’s kernel size, so it skips some pixels. They use 2x2 with stride 2. +0.5%\nOverall, this beat the current state of the art by 0.5%, but using an entirely different and much simpler architecture.\n\n\nTakeaway\nI wonder if they should combine various techniques from more modern things, like diffusion models or NLP models. Maybe MoE with some other techniques is how they made GPT 4? I guess we shall see as I dive deeper into the ML journey and learn more techniques.\n\n\nOther research\nData augmentation techniques like Mixup, Cutmix, RandAugment, Random Erasing, and regularization scehemes like Stochastic Depth and Label Smoothing. Also study inverted bottleneck and BatchNorm vs LayerNorm."
  },
  {
    "objectID": "posts/attention-is-all-you-need/index.html",
    "href": "posts/attention-is-all-you-need/index.html",
    "title": "Attention is all you need",
    "section": "",
    "text": "Summary\nThis paper was groundbreaking, introducing the Transformer model, which replaced the Recurrent Neural Network and Convolutional Neural Network.\n\nScaled Dot-Product Attention/Self Attention\nWe seperate the input tokens into three matrices: the query matrix (Q) which represents the element we want to focus on, the key matrix (K) which is every other word, and the values matrix (V) which is the positional encoding. All also come with weights and biases, which are randomly initialized and then trained for the ensemble of scaled dot-product attention sub-models. That means each different layer outputs different results. The V matrix is determined by using dot product to multiply the query and key and determine similarity, aka attention weight. Softmax is used to make these attention weights probabilities, which then shows the relevance of each key-value pair. Then, you take the weighted sum, to show how much each word is worth. This is different from recurrent neural networks which can keep the individual pairs for better comparisons, but the model makes up for it with multi head attention. In practice, all different query tokens are calculated at once in parallel. In the original model 8 attention heads were used with a 64 token length of each matrix.\n\n\nMulti-Head Attention\nYou take the scaled dot product many different times with the different layers of random weights, and then take the sum of all those. This results in a kind of ensemble of attention, allowing the model to be good with context since it sees the relational patterns. \n\n\nFeed Forward Layer\nEach feed forward layer consists of two linear transformations with a ReLU in between. They use different parameters for each one, which is like two convolutions with kernel size 1.\n\n\nEncoder\nTake the input embeddings (the words converted to a list of tokens) and pass it through a multi head attention layer. Then pass it through a feed forward network layer. That output is put through a residual connection. A residual connection adds the output of the layer to the original input to that layer (shown in the diagram below), which fixes the vanishing gradient problem. The gradients would get incredibly small, but you are instead passing in the original information throughout all of the layers. There are 6 sub layers total in this example. That new output is normalized.\n\n\n\nNetwork\n\n\n\n\nDecoder\nAlso 6 sub layers. After the first multi-head attention layer, it uses another multi-head attention layer instead of a feed-forward layer. For each attention layer, Q comes from the previous decoder layer, K and V come from the encoder’s output. To prevent it from generating new positions, since this is decoding, we need to have it attend to positions that are known. We use two things for this, masking and offsettings. Masking sets the attention scores to negative infinity for positions that correspond to tokens that haven’t been generated yet, so the softmax barely sees them. Offsetting just gives it the tokens before the one it is trying to generate, resulting in the embeddings being offset by one position compared to the input. Now it does the same residual + normalize, then passes it to a feed-forward layer.\n\n\n\nTakeaway\nAI seems like very clever ways to get SGD to work, that’s basically it. Collaborative filtering is like that, transformers are like that, convolutions, etc. There might be other unexplored AI paths I could discover as well!\n\n\nOther research\nThey mentioned label smoothing which I don’t really get, and I need to keep reading papers on Transformer’s because I DO NOT understand them at all even after hours. # I will at some point attempt to implement this, using Andrej Karpathy’s YouTube video on it, but for now I will just leave this here saying it sounds complicated!"
  },
  {
    "objectID": "posts/makemore-from-scratch/index.html",
    "href": "posts/makemore-from-scratch/index.html",
    "title": "MakeMore from Scratch",
    "section": "",
    "text": "Makemore is a model that will make… more, of what you are inputing. This is following a tutorial from Andrej Karpathy.\nclass Value:\n    def __init__(self,data,_children=(),_op='',label=''): #the data is the value, we need children to store the children passed into functions like add and mult, and op to show the operations that came up with those children.\n        self.data = data\n        self.grad = 0 # the derivative of L with respect to this value\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    def __add__(self,other):\n        out = Value(self.data + other.data, (self,other),\"+\")\n        return out\n    def __mul__(self,other):\n        out = Value(self.data * other.data, (self,other),\"*\")\n        return out\na = Value(1.5,label='a')\nb = Value(-5.5,label='b')\nc = Value(0.2,label='c')\na*b,a+b\n\n(Value(data=-8.25), Value(data=-4.0))\ne = a*b; e.label = 'e'\nd = e+c; d.label = 'd'\nf = Value(-2.2,label='f')\nL = d*f; L.label = 'L' # the loss function L\nd._prev\n\n{Value(data=-8.25), Value(data=0.2)}\nd._op\n\n'+'"
  },
  {
    "objectID": "posts/makemore-from-scratch/index.html#proof",
    "href": "posts/makemore-from-scratch/index.html#proof",
    "title": "MakeMore from Scratch",
    "section": "Proof:",
    "text": "Proof:\nlim h-&gt;0 (f(x+h)-f(x))/h\n((d+h) * f - df)/h (df + hf - df)/h (h*f)/h f\n\nd.grad = f.data\nf.grad = d.data\n\n\ndraw_dot(L)\n\n\n\n\ndL / dc since we know dL / dd we can get dd / dc and use it to get dL / dc\nd = c + e\ndd / dc = 1"
  },
  {
    "objectID": "posts/makemore-from-scratch/index.html#proof-1",
    "href": "posts/makemore-from-scratch/index.html#proof-1",
    "title": "MakeMore from Scratch",
    "section": "Proof",
    "text": "Proof\n(f(x+h) - f(x)) / h ((c+h + e) - (c + e))/h (c+h+e-c-e)/h h/h 1\ndd / de = 1 as well\nbut we need dL / dc we use the chain rule, which is basically: if a car travels twice as fast as a bicycle and the bicycle is four times as fast as a walking man, then the car travels 2x4=8 times as fast as the man. So you multiply\nWANT dL / dc KNOW dL/dd and dd/dc\ndL / dc = (dL / dd) * (dd / dc) = (dL / dd) * 1 = dL / dd\n\nc.grad = d.grad\ne.grad = d.grad\n\ndL / da = (dL / de) * (de / da)\nde / da? de / da = b\ndL / da = dL / de * b\n\na.grad = e.grad * b.data\nb.grad = e.grad * a.data\n\n\ndraw_dot(L)\n\n\n\n\n\n# to try and make L go up, we just have to go in the direction of the gradient\na.data += 0.01 * a.grad\nb.data += 0.01 * b.grad\nc.data += 0.01 * c.grad\nd.data += 0.01 * d.grad\n\ne = a * b\nd = e + c\nL = d * f\nprint(L.data)\n\n19.3401846\n\n\n\nIt worked! Now we will do an example with a neuron\n Here is the activation function:\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nplt.plot(np.arange(-5,5,.2), np.tanh(np.arange(-5,5,0.2))); plt.grid()\n\n\n\n\n\n#inputs x1,x2\nx1 = Value(2.0,label='x1')\nx2 = Value(0.0,label='x2')\n# weights w1,w2\nw1 = Value(-3, label='w1')\nw2 = Value(1,label='w2')\n# bias of the neuron\nb = Value(6.7, label='b')\n#x1*w1 + x2*w2+b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\n\ndraw_dot(n)\n\n\n\n\n\nimport math\n# in order to do the activation function tanh, we need to update Value\nclass Value:\n    def __init__(self,data,_children=(),_op='',label=''): #the data is the value, we need children to store the children passed into functions like add and mult, and op to show the operations that came up with those children.\n        self.data = data\n        self.grad = 0 # the derivative of L with respect to this value\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    def __add__(self,other):\n        out = Value(self.data + other.data, (self,other),\"+\")\n        return out\n    def __mul__(self,other):\n        out = Value(self.data * other.data, (self,other),\"*\")\n        return out\n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x)-1)/(math.exp(2*x) + 1)\n        out = Value(t,(self, ), 'tanh')\n        return out\n\n\n#inputs x1,x2\nx1 = Value(2.0,label='x1')\nx2 = Value(0.0,label='x2')\n# weights w1,w2\nw1 = Value(-3, label='w1')\nw2 = Value(1,label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n#x1*w1 + x2*w2+b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\ndraw_dot(o)\n\n\n\n\n\no.grad = 1\n# o = tanh(n)\n# do/dn = 1 - tanh(n)**2\n# do/dn = 1 - o**2\nn.grad = 1 - o.data**2\n\n\ndraw_dot(o)\n\n\n\n\n\nx1w1x2w2.grad = n.grad\nb.grad = n.grad\n\n\nx1w1.grad = x1w1x2w2.grad\nx2w2.grad = x1w1x2w2.grad\n\n\nx2.grad = w2.data * x2w2.grad\nw2.grad = x2.data * x2w2.grad\nx1.grad = w1.data * x1w1.grad\nw1.grad = x1.data * x1w1.grad\n\n\ndraw_dot(o)\n\n\n\n\n\n# now to do the backpropogation\nclass Value:\n    def __init__(self,data,_children=(),_op='',label=''): #the data is the value, we need children to store the children passed into functions like add and mult, and op to show the operations that came up with those children.\n        self.data = data\n        self.grad = 0 # the derivative of L with respect to this value\n        self._backward = lambda: None # NEW\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    def __add__(self,other):\n        out = Value(self.data + other.data, (self,other),\"+\")\n        def _backward():\n            self.grad += 1.0 * out.grad\n            other.grad += 1.0 * out.grad\n        out._backward = _backward\n        return out\n    def __mul__(self,other):\n        out = Value(self.data * other.data, (self,other),\"*\")\n        def _backward():\n            self.grad += out.data * other.grad\n            other.grad += out.data * self.grad\n        out._backward = _backward\n        return out\n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x)-1)/(math.exp(2*x) + 1)\n        out = Value(t,(self, ), 'tanh')\n        def _backward():\n            self.grad = (1 - t**2) * out.grad\n        out._backward = _backward\n        return out\n    def backward(self):\n        topo = []\n        visited = set()\n        def build_topo(v):\n            if v not in visited:\n                visited.add(v)\n                for child in v._prev:\n                    build_topo(child)\n                topo.append(v)\n        build_topo(o)\n        self.grad = 1.0\n        for node in reversed(topo):\n            node._backward()\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\n\n\no.grad = 1.0 # so that multiplication does not multiply by 0\no._backward()\n\n\ndraw_dot(o)\n\n\n\n\n\nn._backward()\nn._backward()\nb._backward() #none\nx1w1x2w2._backward()\nx1w1._backward()\nx2w2._backward()\ndraw_dot(o)\n\n\n\n\n\n# do topological sort\ntopo = []\nvisited = set()\ndef build_topo(v):\n  if v not in visited:\n    visited.add(v)\n    for child in v._prev:\n      build_topo(child)\n    topo.append(v)\nbuild_topo(o)\ntopo\n\n[Value(data=6.881373587019543),\n Value(data=-3.0),\n Value(data=2.0),\n Value(data=-6.0),\n Value(data=0.0),\n Value(data=1.0),\n Value(data=0.0),\n Value(data=-6.0),\n Value(data=0.8813735870195432),\n Value(data=0.7071067811865476)]\n\n\n\no.grad = 1.0\ntopo = []\nvisited = set()\ndef build_topo(v):\n  if v not in visited:\n    visited.add(v)\n    for child in v._prev:\n      build_topo(child)\n    topo.append(v)\nbuild_topo(o)\nfor node in reversed(topo):\n  node._backward()\n\n\no.backward()\n\n\ndraw_dot(o)\n\nSyntaxError: invalid decimal literal (2324353414.py, line 1)\n\n\n\nclass Value:\n  \n  def __init__(self, data, _children=(), _op='', label=''):\n    self.data = data\n    self.grad = 0.0\n    self._backward = lambda: None\n    self._prev = set(_children)\n    self._op = _op\n    self.label = label\n\n  def __repr__(self):\n    return f\"Value(data={self.data})\"\n  \n  def __add__(self, other):\n    out = Value(self.data + other.data, (self, other), '+')\n    \n    def _backward():\n      self.grad += 1.0 * out.grad\n      other.grad += 1.0 * out.grad\n    out._backward = _backward\n    \n    return out\n\n  def __mul__(self, other):\n    out = Value(self.data * other.data, (self, other), '*')\n    \n    def _backward():\n      self.grad += other.data * out.grad\n      other.grad += self.data * out.grad\n    out._backward = _backward\n      \n    return out\n  \n  def tanh(self):\n    x = self.data\n    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n    out = Value(t, (self, ), 'tanh')\n    \n    def _backward():\n      self.grad += (1 - t**2) * out.grad\n    out._backward = _backward\n    \n    return out\n  \n  def backward(self):\n    \n    topo = []\n    visited = set()\n    def build_topo(v):\n      if v not in visited:\n        visited.add(v)\n        for child in v._prev:\n          build_topo(child)\n        topo.append(v)\n    build_topo(self)\n    \n    self.grad = 1.0\n    for node in reversed(topo):\n      node._backward()\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\n\no.backward()\ndraw_dot(o)\n\n\n\n\n\na = Value(3,label='a')\nb = a + a; b.label = 'b' # make the gradients do += rather than = so it doesn't override\nb.backward()\ndraw_dot(b)\n\n\n\n\n\nclass Value:\n  \n  def __init__(self, data, _children=(), _op='', label=''):\n    self.data = data\n    self.grad = 0.0\n    self._backward = lambda: None\n    self._prev = set(_children)\n    self._op = _op\n    self.label = label\n\n  def __repr__(self):\n    return f\"Value(data={self.data})\"\n  \n  def __add__(self, other):\n    other = other if isinstance(other, Value) else Value(other)\n    out = Value(self.data + other.data, (self, other), '+')\n    \n    def _backward():\n      self.grad += 1.0 * out.grad\n      other.grad += 1.0 * out.grad\n    out._backward = _backward\n    \n    return out\n\n  def __mul__(self, other):\n    other = other if isinstance(other, Value) else Value(other)\n    out = Value(self.data * other.data, (self, other), '*')\n    \n    def _backward():\n      self.grad += other.data * out.grad\n      other.grad += self.data * out.grad\n    out._backward = _backward\n      \n    return out\n  \n  def __pow__(self, other):\n    assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n    out = Value(self.data**other, (self,), f'**{other}')\n\n    def _backward():\n        self.grad += other * (self.data ** (other - 1)) * out.grad\n    out._backward = _backward\n\n    return out\n  \n  def __rmul__(self, other): # other * self\n    return self * other\n\n  def __truediv__(self, other): # self / other\n    return self * other**-1\n\n  def __neg__(self): # -self\n    return self * -1\n\n  def __sub__(self, other): # self - other\n    return self + (-other)\n\n  def __radd__(self, other): # other + self\n    return self + other\n\n  def tanh(self):\n    x = self.data\n    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n    out = Value(t, (self, ), 'tanh')\n    \n    def _backward():\n      self.grad += (1 - t**2) * out.grad\n    out._backward = _backward\n    \n    return out\n  \n  def exp(self):\n    x = self.data\n    out = Value(math.exp(x), (self, ), 'exp')\n    \n    def _backward():\n      self.grad += out.data * out.grad # NOTE: in the video I incorrectly used = instead of +=. Fixed here.\n    out._backward = _backward\n    \n    return out\n  \n  \n  def backward(self):\n    \n    topo = []\n    visited = set()\n    def build_topo(v):\n      if v not in visited:\n        visited.add(v)\n        for child in v._prev:\n          build_topo(child)\n        topo.append(v)\n    build_topo(self)\n    \n    self.grad = 1.0\n    for node in reversed(topo):\n      node._backward()\n\n\na = Value(2)\nb = Value(4)\na/b\n\nValue(data=0.5)\n\n\n\n# now with tanh broken up\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\n# ______\ne = (2*n).exp()\no = (e - 1)/(e + 1)\n# _______\no.label = 'o'\no.backward()\ndraw_dot(o)\n\n\n\n\n\n# same thing in PyTorch\nimport torch\n\nx1 = torch.Tensor([2.0]).double()                ; x1.requires_grad = True\nx2 = torch.Tensor([0.0]).double()                ; x2.requires_grad = True\nw1 = torch.Tensor([-3.0]).double()               ; w1.requires_grad = True\nw2 = torch.Tensor([1.0]).double()                ; w2.requires_grad = True\nb = torch.Tensor([6.8813735870195432]).double()  ; b.requires_grad = True\nn = x1*w1 + x2*w2 + b\no = torch.tanh(n)\n\nprint(o.data.item())\no.backward()\n\nprint('---')\nprint('x2', x2.grad.item())\nprint('w2', w2.grad.item())\nprint('x1', x1.grad.item())\nprint('w1', w1.grad.item())\n\n\n0.7071066904050358\n---\nx2 0.5000001283844369\nw2 0.0\nx1 -1.5000003851533106\nw1 1.0000002567688737\n\n\n\nimport random\n\n\n# Building a MLP\nclass Neuron:\n    def __init__(self,nin):\n        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n        self.b = Value(random.uniform(-1,1))\n    def __call__(self,x):\n        # w * x + b\n        # forward pass\n        act = sum((wi*xi for wi,xi in zip(self.w, x)),self.b) # pair up ws with xs\n        out = act.tanh()\n        return out\nx = [2,3]\nn = Neuron(2)\nn(x)\n\nValue(data=-0.5278816907307129)\n\n\n\nclass Layer:\n    def __init__(self, nin, nout,):\n        self.neurons = [Neuron(nin) for _ in range(nout)]\n\n    def __call__(self, x):\n        outs = [n(x) for n in self.neurons]\n        return outs[0] if len(outs) == 1 else outs\nx = [2,3]\nn = Layer(2,3)\nn(x)\n\n[Value(data=0.962111430039211),\n Value(data=-0.9934650406307376),\n Value(data=0.3439500937888263)]\n\n\n\nclass MLP():\n    def __init__(self, nin, nouts):\n        sz = [nin] + nouts\n        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n\n    def __call__(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\nx = [2,3,-1]\nn = MLP(3,[4,4,1])\nn(x)\n\nValue(data=-0.057515384626523336)\n\n\n\ndraw_dot(n(x))\n\n\n\n\n\nxs = [\n  [2.0, 3.0, -1.0],\n  [3.0, -1.0, 0.5],\n  [0.5, 1.0, 1.0],\n  [1.0, 1.0, -1.0],\n]\nys = [1.0, -1.0, -1.0, 1.0] # desired targets\nypred = [n(x) for x in xs]\nypred\n\n[Value(data=-0.057515384626523336),\n Value(data=0.21031897880739908),\n Value(data=-0.23716642272134442),\n Value(data=-0.17695136227658856)]\n\n\n\nloss = sum([(yout - ygt)**2 for ygt, yout in zip(ys,ypred)])\nloss\n\nValue(data=4.550340394971638)\n\n\n\nloss.backward()\n\n\nn.layers[0].neurons[0].w[0].grad\n\n-0.23088023006144023\n\n\n\n#draw_dot(loss)"
  },
  {
    "objectID": "posts/rwkv/index.html",
    "href": "posts/rwkv/index.html",
    "title": "Day 12 - RWKV: Reinventing RNNs for the Transformer Era",
    "section": "",
    "text": "This paper was a good but complex read. It is about Receptance Weighted Key Value models, which are an alternative to Transformers that combine the ideas from both Transformers and RNNs. It came out only a few months ago, so we are yet to see whether or not it can replace Transformers, but it seems to be a good alternative. It has a much lower time complexity and memory complexity, but the problem is that it may lose the ability to see important information in past tokens, since it does not have the full text at any given time. This is due to “funneling information through a single vector representation over many time steps” which allows for less memory usage but also less understanding. Hopefully that isn’t a big issue, but I think it may be. If you paste in an entire book and want it to summarize it, it may struggle to look for individual details. I will need to come back to this paper later, as I didn’t get all the references and various things they included, as well as the design or math in general. It was kind of the same detail with Transformers, the matrices seem a little fuzzy in my brain. What is the difference between Q, V, and K? I don’t know!"
  },
  {
    "objectID": "posts/gpt-two/index.html",
    "href": "posts/gpt-two/index.html",
    "title": "Day 8 - Language Models are Unsupervised Multitask Learners",
    "section": "",
    "text": "Summary\nThis is the GPT-2 paper, an expansion of Day 7’s paper on GPT-1. It is a proof of concept demonstrating a model with an order of magnitude more parameters than the original GPT. It was pre-trained on a WebText dataset made by the creators of this paper, which is a collection of every Reddit post with more than 3 upvotes before 2017. They made various models in ordering complexities, and none of them started overfitting, showing that more training time and bigger models is possible even on just Reddit’s data. Further improvements like more data (other social media sites, various books/articles, Wikepedia, etc), more training time, bigger models, and fine tuning could be used to increase the performance beyond anything imaginable. Fine-tuning was actually not used in this paper, whereas it was for the previous GPT-1, which means there is another big boost it could use. The whole point, though, was to show that the model does not need to be fine-tuned on various tasks, and the one model is enough to do well on all of them. GPT-1 had to be fine-tuned on many different datasets for different tasks, resulting in more time taken by the researchers, whereas GPT-2 could just be fed the data in a normal way and still perform well. This proof of concept is shown in ChatGPT, which is one model that can be used for almost anything. Overall another great expansion of NLP, OpenAI is really a great research company!\n\n\nTakeaway\nModels that take away time from the researchers day are prevalent, but other alternatives are a viable option, using unsupervised training to save time and complexity. This is great, as we may eventually be able to have a universal model that can do everything we need it to, or slowly condense several fields (like question-answer vs translation) into just one (NLP).\n\n\nOther research\nSeveral great research papers in this, as well as some vocab I had never heard of. I actually watched a video on PCA by StatQuest this morning, which gave a great explanation, since that was previously a bit confusing to me. I hope to delve more into Statistics in the coming time, and implement some of these papers I am reading. The vocab was: tractable sampling, perplexity, and Bloom filters. I’ve added the papers to the github page for this project."
  },
  {
    "objectID": "posts/micrograd-from-scratch/index.html",
    "href": "posts/micrograd-from-scratch/index.html",
    "title": "MicroGrad from Scratch with Andrej Karpathy’s tutorial",
    "section": "",
    "text": "I want to learn how Transformers work in depth, but I need a bit of background first. I am going to do all of the tutorials on Andrej Karpathy’s channel, starting with this micrograd from scratch one. That should give me enough background to understand his latest GPT from Scratch tutorial!\nclass Value:\n    def __init__(self,data,_children=(),_op='',label=''): #the data is the value, we need children to store the children passed into functions like add and mult, and op to show the operations that came up with those children.\n        self.data = data\n        self.grad = 0 # the derivative of L with respect to this value\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    def __add__(self,other):\n        out = Value(self.data + other.data, (self,other),\"+\")\n        return out\n    def __mul__(self,other):\n        out = Value(self.data * other.data, (self,other),\"*\")\n        return out\na = Value(1.5,label='a')\nb = Value(-5.5,label='b')\nc = Value(0.2,label='c')\na*b,a+b\n\n(Value(data=-8.25), Value(data=-4.0))\ne = a*b; e.label = 'e'\nd = e+c; d.label = 'd'\nf = Value(-2.2,label='f')\nL = d*f; L.label = 'L' # the loss function L\nd._prev\n\n{Value(data=-8.25), Value(data=0.2)}\nd._op\n\n'+'"
  },
  {
    "objectID": "posts/micrograd-from-scratch/index.html#proof",
    "href": "posts/micrograd-from-scratch/index.html#proof",
    "title": "MicroGrad from Scratch with Andrej Karpathy’s tutorial",
    "section": "Proof:",
    "text": "Proof:\nlim h-&gt;0 (f(x+h)-f(x))/h\n((d+h) * f - df)/h (df + hf - df)/h (h*f)/h f\n\nd.grad = f.data\nf.grad = d.data\n\n\ndraw_dot(L)\n\n\n\n\ndL / dc since we know dL / dd we can get dd / dc and use it to get dL / dc\nd = c + e\ndd / dc = 1"
  },
  {
    "objectID": "posts/micrograd-from-scratch/index.html#proof-1",
    "href": "posts/micrograd-from-scratch/index.html#proof-1",
    "title": "MicroGrad from Scratch with Andrej Karpathy’s tutorial",
    "section": "Proof",
    "text": "Proof\n(f(x+h) - f(x)) / h ((c+h + e) - (c + e))/h (c+h+e-c-e)/h h/h 1\ndd / de = 1 as well\nbut we need dL / dc we use the chain rule, which is basically: if a car travels twice as fast as a bicycle and the bicycle is four times as fast as a walking man, then the car travels 2x4=8 times as fast as the man. So you multiply\nWANT dL / dc KNOW dL/dd and dd/dc\ndL / dc = (dL / dd) * (dd / dc) = (dL / dd) * 1 = dL / dd\n\nc.grad = d.grad\ne.grad = d.grad\n\ndL / da = (dL / de) * (de / da)\nde / da? de / da = b\ndL / da = dL / de * b\n\na.grad = e.grad * b.data\nb.grad = e.grad * a.data\n\n\ndraw_dot(L)\n\n\n\n\n\n# to try and make L go up, we just have to go in the direction of the gradient\na.data += 0.01 * a.grad\nb.data += 0.01 * b.grad\nc.data += 0.01 * c.grad\nd.data += 0.01 * d.grad\n\ne = a * b\nd = e + c\nL = d * f\nprint(L.data)\n\n19.3401846\n\n\n\nIt worked! Now we will do an example with a neuron\n Here is the activation function:\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nplt.plot(np.arange(-5,5,.2), np.tanh(np.arange(-5,5,0.2))); plt.grid()\n\n\n\n\n\n#inputs x1,x2\nx1 = Value(2.0,label='x1')\nx2 = Value(0.0,label='x2')\n# weights w1,w2\nw1 = Value(-3, label='w1')\nw2 = Value(1,label='w2')\n# bias of the neuron\nb = Value(6.7, label='b')\n#x1*w1 + x2*w2+b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\n\ndraw_dot(n)\n\n\n\n\n\nimport math\n# in order to do the activation function tanh, we need to update Value\nclass Value:\n    def __init__(self,data,_children=(),_op='',label=''): #the data is the value, we need children to store the children passed into functions like add and mult, and op to show the operations that came up with those children.\n        self.data = data\n        self.grad = 0 # the derivative of L with respect to this value\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    def __add__(self,other):\n        out = Value(self.data + other.data, (self,other),\"+\")\n        return out\n    def __mul__(self,other):\n        out = Value(self.data * other.data, (self,other),\"*\")\n        return out\n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x)-1)/(math.exp(2*x) + 1)\n        out = Value(t,(self, ), 'tanh')\n        return out\n\n\n#inputs x1,x2\nx1 = Value(2.0,label='x1')\nx2 = Value(0.0,label='x2')\n# weights w1,w2\nw1 = Value(-3, label='w1')\nw2 = Value(1,label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n#x1*w1 + x2*w2+b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\ndraw_dot(o)\n\n\n\n\n\no.grad = 1\n# o = tanh(n)\n# do/dn = 1 - tanh(n)**2\n# do/dn = 1 - o**2\nn.grad = 1 - o.data**2\n\n\ndraw_dot(o)\n\n\n\n\n\nx1w1x2w2.grad = n.grad\nb.grad = n.grad\n\n\nx1w1.grad = x1w1x2w2.grad\nx2w2.grad = x1w1x2w2.grad\n\n\nx2.grad = w2.data * x2w2.grad\nw2.grad = x2.data * x2w2.grad\nx1.grad = w1.data * x1w1.grad\nw1.grad = x1.data * x1w1.grad\n\n\ndraw_dot(o)\n\n\n\n\n\n# now to do the backpropogation\nclass Value:\n    def __init__(self,data,_children=(),_op='',label=''): #the data is the value, we need children to store the children passed into functions like add and mult, and op to show the operations that came up with those children.\n        self.data = data\n        self.grad = 0 # the derivative of L with respect to this value\n        self._backward = lambda: None # NEW\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    def __add__(self,other):\n        out = Value(self.data + other.data, (self,other),\"+\")\n        def _backward():\n            self.grad += 1.0 * out.grad\n            other.grad += 1.0 * out.grad\n        out._backward = _backward\n        return out\n    def __mul__(self,other):\n        out = Value(self.data * other.data, (self,other),\"*\")\n        def _backward():\n            self.grad += out.data * other.grad\n            other.grad += out.data * self.grad\n        out._backward = _backward\n        return out\n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x)-1)/(math.exp(2*x) + 1)\n        out = Value(t,(self, ), 'tanh')\n        def _backward():\n            self.grad = (1 - t**2) * out.grad\n        out._backward = _backward\n        return out\n    def backward(self):\n        topo = []\n        visited = set()\n        def build_topo(v):\n            if v not in visited:\n                visited.add(v)\n                for child in v._prev:\n                    build_topo(child)\n                topo.append(v)\n        build_topo(o)\n        self.grad = 1.0\n        for node in reversed(topo):\n            node._backward()\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\n\n\no.grad = 1.0 # so that multiplication does not multiply by 0\no._backward()\n\n\ndraw_dot(o)\n\n\n\n\n\nn._backward()\nn._backward()\nb._backward() #none\nx1w1x2w2._backward()\nx1w1._backward()\nx2w2._backward()\ndraw_dot(o)\n\n\n\n\n\n# do topological sort\ntopo = []\nvisited = set()\ndef build_topo(v):\n  if v not in visited:\n    visited.add(v)\n    for child in v._prev:\n      build_topo(child)\n    topo.append(v)\nbuild_topo(o)\ntopo\n\n[Value(data=6.881373587019543),\n Value(data=-3.0),\n Value(data=2.0),\n Value(data=-6.0),\n Value(data=0.0),\n Value(data=1.0),\n Value(data=0.0),\n Value(data=-6.0),\n Value(data=0.8813735870195432),\n Value(data=0.7071067811865476)]\n\n\n\no.grad = 1.0\ntopo = []\nvisited = set()\ndef build_topo(v):\n  if v not in visited:\n    visited.add(v)\n    for child in v._prev:\n      build_topo(child)\n    topo.append(v)\nbuild_topo(o)\nfor node in reversed(topo):\n  node._backward()\n\n\no.backward()\n\n\ndraw_dot(o)\n\nSyntaxError: invalid decimal literal (2324353414.py, line 1)\n\n\n\nclass Value:\n  \n  def __init__(self, data, _children=(), _op='', label=''):\n    self.data = data\n    self.grad = 0.0\n    self._backward = lambda: None\n    self._prev = set(_children)\n    self._op = _op\n    self.label = label\n\n  def __repr__(self):\n    return f\"Value(data={self.data})\"\n  \n  def __add__(self, other):\n    out = Value(self.data + other.data, (self, other), '+')\n    \n    def _backward():\n      self.grad += 1.0 * out.grad\n      other.grad += 1.0 * out.grad\n    out._backward = _backward\n    \n    return out\n\n  def __mul__(self, other):\n    out = Value(self.data * other.data, (self, other), '*')\n    \n    def _backward():\n      self.grad += other.data * out.grad\n      other.grad += self.data * out.grad\n    out._backward = _backward\n      \n    return out\n  \n  def tanh(self):\n    x = self.data\n    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n    out = Value(t, (self, ), 'tanh')\n    \n    def _backward():\n      self.grad += (1 - t**2) * out.grad\n    out._backward = _backward\n    \n    return out\n  \n  def backward(self):\n    \n    topo = []\n    visited = set()\n    def build_topo(v):\n      if v not in visited:\n        visited.add(v)\n        for child in v._prev:\n          build_topo(child)\n        topo.append(v)\n    build_topo(self)\n    \n    self.grad = 1.0\n    for node in reversed(topo):\n      node._backward()\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\n\no.backward()\ndraw_dot(o)\n\n\n\n\n\na = Value(3,label='a')\nb = a + a; b.label = 'b' # make the gradients do += rather than = so it doesn't override\nb.backward()\ndraw_dot(b)\n\n\n\n\n\nclass Value:\n  \n  def __init__(self, data, _children=(), _op='', label=''):\n    self.data = data\n    self.grad = 0.0\n    self._backward = lambda: None\n    self._prev = set(_children)\n    self._op = _op\n    self.label = label\n\n  def __repr__(self):\n    return f\"Value(data={self.data})\"\n  \n  def __add__(self, other):\n    other = other if isinstance(other, Value) else Value(other)\n    out = Value(self.data + other.data, (self, other), '+')\n    \n    def _backward():\n      self.grad += 1.0 * out.grad\n      other.grad += 1.0 * out.grad\n    out._backward = _backward\n    \n    return out\n\n  def __mul__(self, other):\n    other = other if isinstance(other, Value) else Value(other)\n    out = Value(self.data * other.data, (self, other), '*')\n    \n    def _backward():\n      self.grad += other.data * out.grad\n      other.grad += self.data * out.grad\n    out._backward = _backward\n      \n    return out\n  \n  def __pow__(self, other):\n    assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n    out = Value(self.data**other, (self,), f'**{other}')\n\n    def _backward():\n        self.grad += other * (self.data ** (other - 1)) * out.grad\n    out._backward = _backward\n\n    return out\n  \n  def __rmul__(self, other): # other * self\n    return self * other\n\n  def __truediv__(self, other): # self / other\n    return self * other**-1\n\n  def __neg__(self): # -self\n    return self * -1\n\n  def __sub__(self, other): # self - other\n    return self + (-other)\n\n  def __radd__(self, other): # other + self\n    return self + other\n\n  def tanh(self):\n    x = self.data\n    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n    out = Value(t, (self, ), 'tanh')\n    \n    def _backward():\n      self.grad += (1 - t**2) * out.grad\n    out._backward = _backward\n    \n    return out\n  \n  def exp(self):\n    x = self.data\n    out = Value(math.exp(x), (self, ), 'exp')\n    \n    def _backward():\n      self.grad += out.data * out.grad # NOTE: in the video I incorrectly used = instead of +=. Fixed here.\n    out._backward = _backward\n    \n    return out\n  \n  \n  def backward(self):\n    \n    topo = []\n    visited = set()\n    def build_topo(v):\n      if v not in visited:\n        visited.add(v)\n        for child in v._prev:\n          build_topo(child)\n        topo.append(v)\n    build_topo(self)\n    \n    self.grad = 1.0\n    for node in reversed(topo):\n      node._backward()\n\n\na = Value(2)\nb = Value(4)\na/b\n\nValue(data=0.5)\n\n\n\n# now with tanh broken up\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\n# ______\ne = (2*n).exp()\no = (e - 1)/(e + 1)\n# _______\no.label = 'o'\no.backward()\ndraw_dot(o)\n\n\n\n\n\n# same thing in PyTorch\nimport torch\n\nx1 = torch.Tensor([2.0]).double()                ; x1.requires_grad = True\nx2 = torch.Tensor([0.0]).double()                ; x2.requires_grad = True\nw1 = torch.Tensor([-3.0]).double()               ; w1.requires_grad = True\nw2 = torch.Tensor([1.0]).double()                ; w2.requires_grad = True\nb = torch.Tensor([6.8813735870195432]).double()  ; b.requires_grad = True\nn = x1*w1 + x2*w2 + b\no = torch.tanh(n)\n\nprint(o.data.item())\no.backward()\n\nprint('---')\nprint('x2', x2.grad.item())\nprint('w2', w2.grad.item())\nprint('x1', x1.grad.item())\nprint('w1', w1.grad.item())\n\n\n0.7071066904050358\n---\nx2 0.5000001283844369\nw2 0.0\nx1 -1.5000003851533106\nw1 1.0000002567688737\n\n\n\nimport random\n\n\n# Building a MLP\nclass Neuron:\n    def __init__(self,nin):\n        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n        self.b = Value(random.uniform(-1,1))\n    def __call__(self,x):\n        # w * x + b\n        # forward pass\n        act = sum((wi*xi for wi,xi in zip(self.w, x)),self.b) # pair up ws with xs\n        out = act.tanh()\n        return out\nx = [2,3]\nn = Neuron(2)\nn(x)\n\nValue(data=-0.5278816907307129)\n\n\n\nclass Layer:\n    def __init__(self, nin, nout,):\n        self.neurons = [Neuron(nin) for _ in range(nout)]\n\n    def __call__(self, x):\n        outs = [n(x) for n in self.neurons]\n        return outs[0] if len(outs) == 1 else outs\nx = [2,3]\nn = Layer(2,3)\nn(x)\n\n[Value(data=0.962111430039211),\n Value(data=-0.9934650406307376),\n Value(data=0.3439500937888263)]\n\n\n\nclass MLP():\n    def __init__(self, nin, nouts):\n        sz = [nin] + nouts\n        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n\n    def __call__(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\nx = [2,3,-1]\nn = MLP(3,[4,4,1])\nn(x)\n\nValue(data=-0.057515384626523336)\n\n\n\ndraw_dot(n(x))\n\n\n\n\n\nxs = [\n  [2.0, 3.0, -1.0],\n  [3.0, -1.0, 0.5],\n  [0.5, 1.0, 1.0],\n  [1.0, 1.0, -1.0],\n]\nys = [1.0, -1.0, -1.0, 1.0] # desired targets\nypred = [n(x) for x in xs]\nypred\n\n[Value(data=-0.057515384626523336),\n Value(data=0.21031897880739908),\n Value(data=-0.23716642272134442),\n Value(data=-0.17695136227658856)]\n\n\n\nloss = sum([(yout - ygt)**2 for ygt, yout in zip(ys,ypred)])\nloss\n\nValue(data=4.550340394971638)\n\n\n\nloss.backward()\n\n\nn.layers[0].neurons[0].w[0].grad\n\n-0.23088023006144023\n\n\n\n#draw_dot(loss)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Jax Bulbrook",
    "section": "",
    "text": "This is where I post all of my discoveries along my coding journey, to keep me accountable. Currently doing deep learning, but I’m always doing something new, so you never know."
  },
  {
    "objectID": "posts/bert/index.html",
    "href": "posts/bert/index.html",
    "title": "Day 16 - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    "section": "",
    "text": "This was a great paper, showing off the ability to edit an image without any background change. It basically masks out a section of your image based on a prompt, then changes that image to your new prompt. It does this via the following: 1. Compute mask. It adds some noise to your image, then denoises it like normal diffusion based models by predicting where the noise is, but it does this for both the original prompt (or no prompt) and the new prompt. Based off this it computes the normalized difference, showing where the two predictions differed in their noise estimates. It then binarizes it to get either black or white for the image, resulting in a mask. This is the brand new topic the paper presented, since previous techniques had to give their mask by hand rather than having it compute one for them. 2. Get two images, one with about half noise and one with a lot of noise. Take the one with lots and do diffusion with the new prompt. Once you hit the point where it has the same amount of noise and the one with about half noise, you can then take the masked pixels and put them in the new image, resulting in the same background. This approach works when you want to change a certain subject, it wouldn’t work if you wanted the whole image to be different as it is mask based."
  },
  {
    "objectID": "posts/RT-2/index.html",
    "href": "posts/RT-2/index.html",
    "title": "Day 15 - RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control",
    "section": "",
    "text": "This was a great paper, showing off the ability to edit an image without any background change. It basically masks out a section of your image based on a prompt, then changes that image to your new prompt. It does this via the following: 1. Compute mask. It adds some noise to your image, then denoises it like normal diffusion based models by predicting where the noise is, but it does this for both the original prompt (or no prompt) and the new prompt. Based off this it computes the normalized difference, showing where the two predictions differed in their noise estimates. It then binarizes it to get either black or white for the image, resulting in a mask. This is the brand new topic the paper presented, since previous techniques had to give their mask by hand rather than having it compute one for them. 2. Get two images, one with about half noise and one with a lot of noise. Take the one with lots and do diffusion with the new prompt. Once you hit the point where it has the same amount of noise and the one with about half noise, you can then take the masked pixels and put them in the new image, resulting in the same background. This approach works when you want to change a certain subject, it wouldn’t work if you wanted the whole image to be different as it is mask based."
  },
  {
    "objectID": "posts/diffedit/index.html",
    "href": "posts/diffedit/index.html",
    "title": "Day 14 - Diffedit: Diffusion-Based Semantic Image Editing with Mask Guidance",
    "section": "",
    "text": "This was a great paper, showing off the ability to edit an image without any background change. It basically masks out a section of your image based on a prompt, then changes that image to your new prompt. It does this via the following: 1. Compute mask. It adds some noise to your image, then denoises it like normal diffusion based models by predicting where the noise is, but it does this for both the original prompt (or no prompt) and the new prompt. Based off this it computes the normalized difference, showing where the two predictions differed in their noise estimates. It then binarizes it to get either black or white for the image, resulting in a mask. This is the brand new topic the paper presented, since previous techniques had to give their mask by hand rather than having it compute one for them. 2. Get two images, one with about half noise and one with a lot of noise. Take the one with lots and do diffusion with the new prompt. Once you hit the point where it has the same amount of noise and the one with about half noise, you can then take the masked pixels and put them in the new image, resulting in the same background. This approach works when you want to change a certain subject, it wouldn’t work if you wanted the whole image to be different as it is mask based."
  },
  {
    "objectID": "posts/cs-to-ml-p1/index.html",
    "href": "posts/cs-to-ml-p1/index.html",
    "title": "Computer Science to Machine Learning - An intuitive understanding of ML for coders (Part 1)",
    "section": "",
    "text": "Summary\nThis tutorial is meant to give an intuitive explanation of machine learning for those that are already familiar with computer science, specifically Python and OOP. If you aren’t, I would highly suggest learning to code before learning AI, as it will be very challenging otherwise. Check out the amazing 100 Days of Python Course to do so. But this mini-course assumes no previous knowledge of the field. In fact, I was in the same position roughly a year ago, having gotten interested in ML with the release of ChatGPT. I couldn’t possibly imagine how they are able to program so many different outputs, or how they teach a computer to do it for them. Roughly a year later and my path has deviated several times, as there are so many resources out there it’s hard to keep track. My list of links, videos, and books to read is over 500, and that is unsustainable for someone trying to transition from CS to the newly popular (and high paying) ML. I’m not at all good at math or theory, I prefer using code as an example, but in some cases there is a need to understand the underlying theory, for which I apologize in advance.\n\n\nCourse outline\nI am going to be documenting the various ideas on the journey to a career in Machine Learning, so this will probably be ongoing, but for now here is what you will learn:\n\nAn intuitive understanding of a neural network (this post)\nImplementing a simple digit classifier with PyTorch\nBehind the scenes: How Backpropogation works\nA guide to the confusing aspects of the Transformer\nHow Stable Diffusion works\nTips to make your model better (dropout, layer norm, nonlinearity, etc)\n\n\n\nWhat is a neural network?\nNeural networks are simply used to refer to a complex mathematical expression. It is a way to represent any function with a series of “parameters”. For now, you can think of it as a black box, where you pass in information and get out the correct information. This neural network can have it’s complexity increased or decreased, depending on the complexity of the relationship it needs to model. The reason it’s so special, and the reason everyone cares so much about it, is that its a universal function approximator. So it could graph something as simple as x^2 or sin(x), yes, but it can also be expanded to anything you can put into a series of numbers.\nSo what if you need to figure out if an image is a cat or a dog? Just convert each pixel to a number going from 0 (white) to 1 (black), and feed that in, to get the answer. We could manually figure this out, by writing some incredibly long function with thousands of different variables, but mathematicians would very quickly get tired of that. And how do you figure out what the numbers are? It makes no intuitive sense to us, but computers don’t need intuition. The beauty of a neural network is that you can give it a bunch of data it needs to classify along with the result, and it will figure out how to do that. It does need some way of figuring out if it’s right or wrong, though, or else it would just spit out random answers forever and think it’s getting everything write.\nBut how does this magical function approximator work? It’s actually modelled after our own brains, which may be why it can now do many of the same things we can do. Here is a simple graph, one that can classify someone as male or female given their height and weight:  It looks a bit confusing at first, but it’s actually very simple. You start with an input layer, with your two numbers you are feeding it (weight and height). There is no need to transform these from our language (words) computer language (numbers) since they already are! Then, you have what’s called a hidden layer. This goes in between the input and output layer, and it is used to give the model a bit more context. If we were only allowed to have one layer, then the weight and height would have to have some number that directly turns them into gender (1 or 0). It’s a bit more complicated than that, so you give the model one (or many) extra layers to process the information a bit better. One is enough, but when you get to image classifiers like ResNet, they have up to 50 layers!\nTo calculate h1 and h2, which is the data you then pass on as the new inputs to the next layer, you take some weights and a bias. In this case, the math for h1 would be (weight*w1) + (height*w2) + b1. If you aren’t a math person, that’s ok. You are basically taking the weight and height and multiplying them by some number to transform them more towards the number. In this case, the weight is probably in the triple digits, if in pounds, and the height is probably mid 50s in inches. This is a long way away from somehow changing it into a number from 0 to 1 for the gender, so we first need to multiply them by some number. In this case, it would be a very small number like 0.1 or even 0.01, which would turn 100 into 10 or 1 respectively. This is a bit closer to our number, which is why we use weights. Then we need some way to also give it the information from the height, which is calculated in the same way. We can add them together, but that may still not be enough (or too much). We also add a bias, which is just some set number, to make the numbers more standardized. In this case, the weight and height put together would proably go over 1, so the bias could be something like -1 to bring it back to a range of 0-1. And that’s a basic Neural Network!\n\n\nHow would this work in a practical sense?\nWe are now going to be introduced into the power of PyTorch, one of many machine learning frameworks for Python. Most of them are roughly the same, so it doesn’t matter what you start with, but this one is most popular in AI research and is growing in careers as well. You can follow along with this tutorial via this Jupyter Notebook. If you don’t know what a Jupyter notebook is, it’s basically a collection of code blocks that you can run 1 by 1 rather than executing a whole script at once. If you don’t have VSCode, Jupyter Lab, or Jupyter Notebook installed on a local computer, you can run this in Kaggle as well, but I won’t cover that here. We are going to be making a simple function classifier, to approximate things like sin(x) and x^2. This will help understand the basics, like datasets, training a neural network, and nonlinearity.\n\n# Step one, install the required libraries\n!pip install pytorch numpy matplotlib # a ! before a line means run in the command line rather than in Python\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport matplotlib.pyplot as plt # I had an error and had to also install ipywidgets in case you run into that\nplt.style.use('_mpl-gallery')\n\n\n# Some tuneable variables that will be explained later\n# cpu or gpu\ndevice = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n\nThe following helper functions are just normal programming, with pyplot, so I won’t go too far into detail\n\nclass Net(torch.nn.Module):\n    def __init__(self, num_params=3):\n        super().__init__()\n        self.num_params = num_params\n        self.params = torch.nn.Parameter(torch.randn(num_params) * 0.01)  # Manually initialize with small values\n    def forward(self, x):\n        y = torch.zeros_like(x)\n        for idx in range(self.num_params):\n            y += self.params[idx] * torch.pow(x, idx)\n        return y\n\n\nmodel = nn.Sequential(\n    nn.Linear(1, 10),\n    nn.ReLU(),\n    nn.Linear(10, 50),\n    nn.ReLU(),\n    nn.Linear(50, 10),\n    nn.ReLU(),\n    nn.Linear(10, 1)\n)\n\n\nx = torch.linspace(-15, 15, 2000).unsqueeze(1)\ny = torch.sin(x)\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\nfor t in range(2000):\n    optimizer.zero_grad()\n    # Forward pass: Compute predicted y by passing x to the model\n    y_pred = model(x)\n\n    # Compute and print loss\n    loss = F.mse_loss(y_pred, y)\n    if t % 100 == 99:\n        print(t, loss.item())\n\n    # Zero gradients, perform a backward pass, and update the weights.\n    \n    loss.backward()\n    optimizer.step()\n\n99 0.3614107668399811\n199 0.34806376695632935\n299 0.3532806932926178\n399 0.3499610722064972\n499 0.3483750522136688\n599 0.34798097610473633\n699 0.34804192185401917\n799 0.3481113314628601\n899 0.3483879566192627\n999 0.3488181233406067\n1099 0.34910497069358826\n1199 0.3490227162837982\n1299 0.3482523262500763\n1399 0.33550703525543213\n1499 0.327591210603714\n1599 0.32440435886383057\n1699 0.32894811034202576\n1799 0.34607040882110596\n1899 0.32680436968803406\n1999 0.3409467935562134\n\n\n\n# Test the model\ntest_x = torch.linspace(-15, 15, 2000).unsqueeze(1)\npredicted_y = model(test_x)\n\n# Convert tensor data back to numpy arrays for plotting\ntest_x = test_x.numpy()\npredicted_y = predicted_y.detach().numpy()\ntrue_y = np.sin(test_x)\n\n# Plot the results\nplt.figure(figsize=(8, 6))\nplt.plot(test_x, true_y, \"r-\", label='True Function: x^2')\nplt.plot(test_x, predicted_y, label='Predicted Function', linestyle='dashed')\nplt.legend()\nplt.show()"
  }
]